# Exploring-Efficient-Hardware-Accelerator-for-Learning-based-Image-Compression

X-LIC is a framework to efficiently explore the design spaces of LIC accelerators. Here, we provide an FPGA demo of LIC design in INT16 precision.

This FPGA demo includes:
* Training and Inference Settings
* The python script of Model Extraction
* Quantization and software-simulation
* HLS Design
* Hardware/Software project for target ARM+FPGA platform

## Training and Inference Settings
Training framework is **Tensorflow-2.13** with **[Tensorflow-compression](https://github.com/tensorflow/compression)** library, and training settings follow [default configuration](https://github.com/tensorflow/compression/blob/master/models/bls2017.py). 
We use E2E model [[1](https://arxiv.org/abs/1611.01704)] to evaluate our framework.
The evaluation platform is Xilinx's ARM+FPGA MPSoC **ZCU102**, and toolchain version is Vivado/Vivado HLS/Vitis **v2019.2**.

**Training in Tensorflow**
```  
nohup python3 bls2017.py -V train --train_glob '/xxx/train_dataset/*.png' --batchsize 16 --epochs 200 --lambda 0.125 > train.log 2>&1 &
cat train.log | tail -n 50
```
Default model path is **bls2017**, we move this repo to **bls2017_0xxxx** for different lambda params. Generally, bigger lambda results in higher bpp & PSNR. In **bls2017_0125**, we provide pre-train model with lambda=0.125.

**Inference in Tensorflow**
``` 
# Inference_encoder
python3 bls2017.py --model_path bls2017 compress abigail-keenan-27293.png

# Inference_decoder
python3 bls2017.py --model_path bls2017 decompress abigail-keenan-27293.png.tfci rec.png
``` 
We use abigail-keenan-27293.png from [CLIC traing dataset](http://clic.compression.cc/2021/tasks/index.html) as test image in this demo.

## Model Extraction
```
python3 bls2017_me.py --model_path bls2017_0125
```
We also provide extracted weight params with lambda=0.125 in **bin** repo.

In E2E model, convolution/transposed-convloution (CONV/TPCV) operators' weights require IRFFT transformation to generate 2D weights. 
And, processed weights in TPCV operator require a 180Â° reversal in kernel size dimensions.

## Quantization and SW-Sim
### FT32-Simulation 
After Model Extraction, weight/bias should be reordered to match the bitwidth of databus (Bit<sub>DB</sub>=Bit<sub>Data</sub>&times;N<sub>LN</sub>) or increase burst length. => **make gen_reorder_w_sk_f32c**

**make test_as_rsc_f32c_NTP** just tests the extracted params and optimized-TPCV in **FT32** precision. Hardware/Software design params (e.g., T*, P*) could be configured in sw_sim's **Makefile**.

```
X-LIC/sw_sim$ make gen_reorder_w_sk_f32c 
g++ -O3 -w -o test_reorder weight_reorder_sk_f32c.cpp -I . -lm
./test_reorder  8 8 64
ana_0: ic,oc= [3, 128], data_num =    31104, add_offset = 0.
gdn_0: ic,oc= [128, 128], data_num =    16384, add_offset = 0.
ana_1: ic,oc= [128, 128], data_num =   409600, add_offset = 0.
gdn_1: ic,oc= [128, 128], data_num =    16384, add_offset = 0.
ana_2: ic,oc= [128, 128], data_num =   409600, add_offset = 0.
bias[ 0] data_num=  128.
bias[ 1] data_num=  128.
bias[ 2] data_num=  128.
bias[ 3] data_num=  128.
syn_0: ic,oc= [128, 128], data_num =   409600, add_offset = 0.
igdn_0: ic,oc= [128, 128], data_num =    16384, add_offset = 0.
syn_1: ic,oc= [128, 128], data_num =   409600, add_offset = 0.
igdn_1: ic,oc= [128, 128], data_num =    16384, add_offset = 0.
syn_2: ic,oc= [128, 3], data_num =    31104, add_offset = 51840.
bias[ 0] data_num=  128.
bias[ 1] data_num=  128.
bias[ 2] data_num=  128.
bias[ 3] data_num=  128.
bias[ 4] data_num=    3, add 5.

X-LIC/sw_sim$ make test_as_rsc_f32c_NTP 
g++ -O3 -w -o test_ana main_ana_chw_rsc_0_NTP.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
g++ -O3 -w -o test_syn main_syn_chw_rsc_0_NTP.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
./test_ana ../img/abigail-keenan-27293.png
Input img:../img/abigail-keenan-27293.png
 w=2048,h=1365,c=3
ana_kernel_w_f32rc.bin's data size is 3532288
ana_bias_f32c.bin's data size is 2048
ana_0: ic_h_w= [3, 1365, 2048], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 22.46917
gdn_0: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 8.32909
ana_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 51.02505
gdn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 2.07788
ana_2: ic_h_w= [128, 171, 256], oc_h_w= [128, 86, 128], w_aoffset=0, bias_aoffset=0, lat= 12.83056
ana_output: ana_q_out_chw.bin, h_w_c= [86, 128, 128]

./test_syn ana_q_out_chw.bin ana_IHW_OHW_set.bin
ana_IHW_OHW_set.bin's data size is 80
fm_max_size_calc = 44826624
syn_kernel_w_T_f32rc.bin's data size is 3739648
syn_bias_f32c.bin's data size is 2080
syn_input: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
syn_0: ic_h_w= [128, 86, 128], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 13.06222
igdn_0: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 2.09547
syn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 51.77906
igdn_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 8.38848
syn_2: ic_h_w= [128, 342, 512], oc_h_w= [3, 1365, 2048], w_aoffset=51840, bias_aoffset=5, lat= 348.81109
save_png(s): 0.96445
syn_output: recon_c.png, h_w_c= [1365, 2048, 3]
```
We simplify the X-LIC flow and just reserve the FPGA part in this demo (skip the **Q/IQ** and **entropy coding** in codec). **ana_q_out_chw.bin** is the transformed **y** after encoder.

**img/abigail-keenan-27293.png (Left); img/recon_f32c.png (Right)**
<div style="display: flex;">
    <img src="img/abigail-keenan-27293.png" width="45%" alt="First Image"/> 
    <div style="width: 2%;"></div>
    <img src="img/recon_f32c.png" width="45%" alt="Second Image"/>
</div>

### INT16-Simulation
We would further optimize the flow. Generated image is stored as **img/recon_i16c.png**.

**make gen_iofm_sk_i16c**

**make gen_reorder_w_sk_i16c_scale**

**make test_iofm_reorder_w_sk_i16c**

**make gen_interQ_sk_i16c**

**make test_interQ_sk_i16c**

**make test_interQ_sk_i16c_sr_cb**

**make test_as_rsc_i16c_NTP**
```
X-LIC/sw_sim$ make gen_iofm_sk_i16c
g++ -O3 -w -o test_ana main_ana_chw_rsc_0_1.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
g++ -O3 -w -o test_syn main_syn_chw_rsc_0_1.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
./test_ana ../img/abigail-keenan-27293.png
Input img:../img/abigail-keenan-27293.png
 w=2048,h=1365,c=3
ana_kernel_w_f32rc.bin's data size is 3532288
read weight byte_num = 883072
ana_bias_f32c.bin's data size is 2048
512
read bias byte_num = 2048
5
5
Layer[x]'s fm, c=           3, hw=     2795520 sum2_error = 254.3543486,min_error=0.0000000,max_error=0.0000608
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 1267.6597215,min_error=0.0000000,max_error=0.0005072
ana_0: ic_h_w= [3, 1365, 2048], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 12.15357
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 1267.6597215,min_error=0.0000000,max_error=0.0005072
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 504.9331022,min_error=0.0000000,max_error=0.0001407
gdn_0: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 2.85378
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 504.9331022,min_error=0.0000000,max_error=0.0001407
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 701.4870437,min_error=0.0000000,max_error=0.0005592
ana_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 14.57388
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 701.4870437,min_error=0.0000000,max_error=0.0005592
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 513.0098760,min_error=0.0000000,max_error=0.0007035
gdn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 0.71541
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 513.0098760,min_error=0.0000000,max_error=0.0007035
Layer[x]'s fm, c=         128, hw=       11008 sum2_error = 722.1750469,min_error=0.0000000,max_error=0.0106125
ana_2: ic_h_w= [128, 171, 256], oc_h_w= [128, 86, 128], w_aoffset=0, bias_aoffset=0, lat= 3.66043
ana_ifm_scale:
1.00000 1.00000 1.00000 0.00000 0.00000 0.00000 0.00000 0.00000 1.04425 0.62495 2.93248 0.88982 0.93810 0.83181 0.42450 1.01287 0.68104 0.62023 0.67346 0.79973 1.12036 4.62970 2.77218 1.88367 0.60425 3.40850 0.59115 0.68167 0.43710 0.76521 1.68256 4.54003 0.72488 0.96670 1.01727 1.03470 2.30675 2.54538 1.63842 1.85761 1.46157 0.59151 0.73197 0.42650 3.63420 2.12363 0.59551 0.91118 3.90330 3.27581 1.37407 3.92908 2.77262 1.02078 0.84844 1.07360 1.24768 1.66969 0.76150 0.69100 5.06343 3.42028 3.36294 0.78447 0.84336 4.66121 0.63128 0.79043 3.14063 1.58447 0.53159 5.46271 0.55870 0.99670 0.59848 0.75128 1.02967 1.17792 0.78858 0.83171 1.03050 0.57010 0.59512 3.79248 0.69072 0.69684 3.77207 0.69174 0.71728 0.61656 1.43105 2.65210 0.70405 5.11699 4.75064 4.99929 2.05587 1.07416 0.37079 1.59962 0.94927 4.41827 6.93615 1.34509 6.88795 0.65560 0.59285 0.70080 0.89152 1.36499 0.69952 3.75552 5.49491 8.30993 0.74211 1.79726 1.94992 4.94922 4.06063 3.25333 0.67401 0.76005 1.31028 0.87580 1.12902 1.95507 0.65413 0.60787 3.91335 3.03568 1.02701 0.56711 0.81763 1.07573 0.92845 3.56035 1.12675 0.58488 0.84079 0.80118 0.37375 0.98104 0.40641 0.40793 0.62777 0.56514 0.66214 0.73429 1.06587 0.72565 2.30461 0.75456 0.57506 0.34772 0.60964 0.56160 0.42337 0.72208 0.39901 0.73894 0.71957 0.86869 0.97470 0.60330 0.74716 0.46817 0.49625 1.16835 1.30053 0.41120 0.70814 0.40169 0.47511 0.43650 0.53393 0.78582 0.59050 0.51060 0.65568 0.94782 0.63191 0.95374 0.81194 0.99032 1.17139 0.62761 0.72373 0.63780 1.13423 1.01508 0.65859 0.68937 0.78838 0.68506 0.58199 0.75018 0.83309 0.36699 0.48441 0.82757 0.51141 0.49312 0.52854 0.68589 0.90826 0.99311 0.91035 0.78938 0.87862 0.54207 0.54485 0.76467 0.64524 0.67600 0.77132 0.62639 0.85110 0.91906 1.18078 0.59847 0.47443 0.60453 0.95236 0.77966 0.31609 1.08801 0.36801 0.70814 0.74807 0.73403 1.14366 1.11735 1.05922 0.60449 0.54397 0.60421 0.80022 0.35902 0.66056 0.72750 0.73268 1.31882 0.66840 1.31412 1.20590 0.86688 0.42497 0.86068 0.63462 0.71839 0.41682 0.78875 0.94051 0.73272 0.61550 0.39899 0.81024 0.68783 0.84802 0.52902 0.75538 0.92273 0.78469 0.82802 5.99455 1.64288 3.70661 1.74004 3.19769 3.16296 5.67746 1.68846 4.34194 5.05186 4.86045 3.20481 9.00715 2.15339 7.47463 3.20023 1.29850 3.66940 4.79219 2.98720 3.43619 2.99390 2.82671 4.21205 1.69613 1.31921 9.02655 1.19604 5.41815 2.94629 4.79243 4.26866 4.65745 5.18976 1.50121 4.41384 6.36600 6.70750 8.70739 2.58114 2.29675 3.51741 7.97895 2.30148 4.58952 6.84997 1.76403 7.03261 6.07678 2.00726 2.07237 4.44493 2.64911 6.22087 1.28325 1.01883 6.44664 1.90985 2.82407 8.27058 5.56986 1.47867 1.54551 1.23864 5.92579 4.97190 6.30540 3.28502 4.31829 2.32048 6.10041 7.53791 7.94097 1.71002 8.45735 5.04222 4.80994 1.26185 2.57271 5.45044 4.05668 1.77340 5.22278 3.03243 3.35903 3.30549 9.16216 2.74242 7.98884 3.79263 3.18808 4.55433 2.85812 5.97239 3.65383 3.62182 3.30689 3.32894 7.21128 4.29757 4.86867 5.88612 6.00459 7.68127 1.51168 1.23323 3.43328 3.65761 1.94711 4.71300 4.01139 6.26493 6.73121 2.12647 6.19392 2.51191 4.28502 1.11958 1.39345 1.73596 3.46797 4.94411 2.02593 5.63016 4.34094 2.83620 3.88870 1.76596 4.02919 0.88364 1.30228 1.23395 2.11363 1.02381 5.74958 1.20031 4.00917 2.62599 2.88049 2.27712 10.65053 0.82367 7.88349 0.73656 0.88081 3.28836 4.37567 0.63258 2.97995 1.21196 2.40733 1.74699 1.21865 0.77820 11.52605 0.73808 3.51737 0.78797 3.04823 3.12746 4.07051 6.08955 1.00985 4.04616 4.61601 6.90508 10.69246 1.01182 0.86409 2.82682 9.71655 1.57355 3.13943 8.18039 0.66513 5.37808 7.33720 1.18145 0.69785 2.13598 1.80098 5.64656 0.74797 0.70226 7.91488 1.31735 1.85997 10.63217 2.86538 0.91774 1.06447 0.58711 2.32172 3.98707 6.71498 2.33302 1.89997 0.99222 5.95732 1.54937 3.48505 0.70351 1.92873 2.40517 4.07433 0.70496 1.05688 5.25445 1.41155 1.38029 1.72897 2.30710 1.50985 2.10373 8.34908 1.83627 11.17551 3.40066 2.64744 1.91508 1.17542 6.05819 2.48946 3.26859 0.77043 1.53936 2.26561 3.98668 1.04816 4.57373 4.15669 4.32048 0.85007 0.73282 1.48988 3.40272 0.93302 4.55302 2.17101 6.46098 7.26542 0.65324 6.61069 2.03388 1.41066 0.78510 0.72035 0.99697 1.33604 4.38341 0.44840 1.50039 1.43274 0.52683 1.55951 1.13887 
ana_ofm_scale:
1.04425 0.62495 2.93248 0.88982 0.93810 0.83181 0.42450 1.01287 0.68104 0.62023 0.67346 0.79973 1.12036 4.62970 2.77218 1.88367 0.60425 3.40850 0.59115 0.68167 0.43710 0.76521 1.68256 4.54003 0.72488 0.96670 1.01727 1.03470 2.30675 2.54538 1.63842 1.85761 1.46157 0.59151 0.73197 0.42650 3.63420 2.12363 0.59551 0.91118 3.90330 3.27581 1.37407 3.92908 2.77262 1.02078 0.84844 1.07360 1.24768 1.66969 0.76150 0.69100 5.06343 3.42028 3.36294 0.78447 0.84336 4.66121 0.63128 0.79043 3.14063 1.58447 0.53159 5.46271 0.55870 0.99670 0.59848 0.75128 1.02967 1.17792 0.78858 0.83171 1.03050 0.57010 0.59512 3.79248 0.69072 0.69684 3.77207 0.69174 0.71728 0.61656 1.43105 2.65210 0.70405 5.11699 4.75064 4.99929 2.05587 1.07416 0.37079 1.59962 0.94927 4.41827 6.93615 1.34509 6.88795 0.65560 0.59285 0.70080 0.89152 1.36499 0.69952 3.75552 5.49491 8.30993 0.74211 1.79726 1.94992 4.94922 4.06063 3.25333 0.67401 0.76005 1.31028 0.87580 1.12902 1.95507 0.65413 0.60787 3.91335 3.03568 1.02701 0.56711 0.81763 1.07573 0.92845 3.56035 1.12675 0.58488 0.84079 0.80118 0.37375 0.98104 0.40641 0.40793 0.62777 0.56514 0.66214 0.73429 1.06587 0.72565 2.30461 0.75456 0.57506 0.34772 0.60964 0.56160 0.42337 0.72208 0.39901 0.73894 0.71957 0.86869 0.97470 0.60330 0.74716 0.46817 0.49625 1.16835 1.30053 0.41120 0.70814 0.40169 0.47511 0.43650 0.53393 0.78582 0.59050 0.51060 0.65568 0.94782 0.63191 0.95374 0.81194 0.99032 1.17139 0.62761 0.72373 0.63780 1.13423 1.01508 0.65859 0.68937 0.78838 0.68506 0.58199 0.75018 0.83309 0.36699 0.48441 0.82757 0.51141 0.49312 0.52854 0.68589 0.90826 0.99311 0.91035 0.78938 0.87862 0.54207 0.54485 0.76467 0.64524 0.67600 0.77132 0.62639 0.85110 0.91906 1.18078 0.59847 0.47443 0.60453 0.95236 0.77966 0.31609 1.08801 0.36801 0.70814 0.74807 0.73403 1.14366 1.11735 1.05922 0.60449 0.54397 0.60421 0.80022 0.35902 0.66056 0.72750 0.73268 1.31882 0.66840 1.31412 1.20590 0.86688 0.42497 0.86068 0.63462 0.71839 0.41682 0.78875 0.94051 0.73272 0.61550 0.39899 0.81024 0.68783 0.84802 0.52902 0.75538 0.92273 0.78469 0.82802 5.99455 1.64288 3.70661 1.74004 3.19769 3.16296 5.67746 1.68846 4.34194 5.05186 4.86045 3.20481 9.00715 2.15339 7.47463 3.20023 1.29850 3.66940 4.79219 2.98720 3.43619 2.99390 2.82671 4.21205 1.69613 1.31921 9.02655 1.19604 5.41815 2.94629 4.79243 4.26866 4.65745 5.18976 1.50121 4.41384 6.36600 6.70750 8.70739 2.58114 2.29675 3.51741 7.97895 2.30148 4.58952 6.84997 1.76403 7.03261 6.07678 2.00726 2.07237 4.44493 2.64911 6.22087 1.28325 1.01883 6.44664 1.90985 2.82407 8.27058 5.56986 1.47867 1.54551 1.23864 5.92579 4.97190 6.30540 3.28502 4.31829 2.32048 6.10041 7.53791 7.94097 1.71002 8.45735 5.04222 4.80994 1.26185 2.57271 5.45044 4.05668 1.77340 5.22278 3.03243 3.35903 3.30549 9.16216 2.74242 7.98884 3.79263 3.18808 4.55433 2.85812 5.97239 3.65383 3.62182 3.30689 3.32894 7.21128 4.29757 4.86867 5.88612 6.00459 7.68127 1.51168 1.23323 3.43328 3.65761 1.94711 4.71300 4.01139 6.26493 6.73121 2.12647 6.19392 2.51191 4.28502 1.11958 1.39345 1.73596 3.46797 4.94411 2.02593 5.63016 4.34094 2.83620 3.88870 1.76596 4.02919 0.88364 1.30228 1.23395 2.11363 1.02381 5.74958 1.20031 4.00917 2.62599 2.88049 2.27712 10.65053 0.82367 7.88349 0.73656 0.88081 3.28836 4.37567 0.63258 2.97995 1.21196 2.40733 1.74699 1.21865 0.77820 11.52605 0.73808 3.51737 0.78797 3.04823 3.12746 4.07051 6.08955 1.00985 4.04616 4.61601 6.90508 10.69246 1.01182 0.86409 2.82682 9.71655 1.57355 3.13943 8.18039 0.66513 5.37808 7.33720 1.18145 0.69785 2.13598 1.80098 5.64656 0.74797 0.70226 7.91488 1.31735 1.85997 10.63217 2.86538 0.91774 1.06447 0.58711 2.32172 3.98707 6.71498 2.33302 1.89997 0.99222 5.95732 1.54937 3.48505 0.70351 1.92873 2.40517 4.07433 0.70496 1.05688 5.25445 1.41155 1.38029 1.72897 2.30710 1.50985 2.10373 8.34908 1.83627 11.17551 3.40066 2.64744 1.91508 1.17542 6.05819 2.48946 3.26859 0.77043 1.53936 2.26561 3.98668 1.04816 4.57373 4.15669 4.32048 0.85007 0.73282 1.48988 3.40272 0.93302 4.55302 2.17101 6.46098 7.26542 0.65324 6.61069 2.03388 1.41066 0.78510 0.72035 0.99697 1.33604 4.38341 0.44840 1.50039 1.43274 0.52683 1.55951 1.13887 12.56284 89.28978 101.89207 39.41132 11.23489 5.76638 8.63292 17.53730 5.69055 13.90051 3.48238 12.81608 13.78771 17.42816 20.71860 6.17125 7.52657 5.70308 7.44641 9.09432 4.13989 10.09693 5.39967 15.46922 10.48471 5.35861 7.22291 4.14580 7.11882 29.35995 10.01184 7.28116 8.34451 20.25339 12.03590 22.89722 3.97772 9.54541 3.07284 5.12793 14.32651 8.93516 31.58894 15.41181 6.19151 33.92872 6.34196 4.96311 5.58616 21.68066 37.27899 4.53742 4.43894 3.62784 6.37714 10.91814 6.73010 6.15850 8.77820 13.08802 3.90606 5.57609 21.16168 40.69180 10.45492 5.64689 8.68413 10.85867 50.34693 6.28488 12.57538 10.65346 8.38374 26.64158 3.70885 173.88365 38.11555 4.14880 3.74274 33.39157 13.05547 6.70669 9.16730 29.62900 128.36635 18.87201 25.44113 8.84134 21.05356 6.05001 4.01159 53.45878 5.41756 11.52960 4.59985 20.66604 16.10008 11.68180 5.16774 15.63006 27.04703 16.62606 8.09385 30.67252 8.18550 4.82159 3.69058 3.79785 3.50443 4.31370 7.20820 9.20347 4.92465 13.00641 11.28553 83.86455 16.12357 5.37966 9.07668 13.00888 17.09692 15.36582 11.42200 5.86458 16.93136 12.99391 16.69906 12.17518 
ana_output: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
./test_syn ana_q_out_chw.bin ana_IHW_OHW_set.bin
ana_IHW_OHW_set.bin's data size is 80
fm_max_size_calc = 44826624
syn_kernel_w_T_f32rc.bin's data size is 3739648
read weight byte_num = 934912
syn_bias_f32c.bin's data size is 2080
520
read bias byte_num = 2080
5
5
syn_input: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
Layer[x]'s fm, c=         128, hw=       11008 sum2_error = 722.1750469,min_error=0.0000000,max_error=0.0106125
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 4290.2885983,min_error=0.0000000,max_error=0.0039738
syn_0: ic_h_w= [128, 86, 128], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 3.68396
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 4290.2885983,min_error=0.0000000,max_error=0.0039738
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 180.8438204,min_error=0.0000000,max_error=0.0008379
igdn_0: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 0.72930
Layer[x]'s fm, c=         128, hw=       43776 sum2_error = 180.8438204,min_error=0.0000000,max_error=0.0008379
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 1702.5277393,min_error=0.0000000,max_error=0.0002721
syn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 14.71524
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 1702.5277393,min_error=0.0000000,max_error=0.0002721
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 533.9610108,min_error=0.0000000,max_error=0.0001443
igdn_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 2.93352
Layer[x]'s fm, c=         128, hw=      175104 sum2_error = 533.9610108,min_error=0.0000000,max_error=0.0001443
Layer[x]'s fm, c=           3, hw=     2795520 sum2_error = 273.4954069,min_error=0.0000000,max_error=0.0000705
syn_2: ic_h_w= [128, 342, 512], oc_h_w= [3, 1365, 2048], w_aoffset=51840, bias_aoffset=5, lat= 94.83494
syn_ifm_scale:
12.56284 89.28978 101.89207 39.41132 11.23489 5.76638 8.63292 17.53730 5.69055 13.90051 3.48238 12.81608 13.78771 17.42816 20.71860 6.17125 7.52657 5.70308 7.44641 9.09432 4.13989 10.09693 5.39967 15.46922 10.48471 5.35861 7.22291 4.14580 7.11882 29.35995 10.01184 7.28116 8.34451 20.25339 12.03590 22.89722 3.97772 9.54541 3.07284 5.12793 14.32651 8.93516 31.58894 15.41181 6.19151 33.92872 6.34196 4.96311 5.58616 21.68066 37.27899 4.53742 4.43894 3.62784 6.37714 10.91814 6.73010 6.15850 8.77820 13.08802 3.90606 5.57609 21.16168 40.69180 10.45492 5.64689 8.68413 10.85867 50.34693 6.28488 12.57538 10.65346 8.38374 26.64158 3.70885 173.88365 38.11555 4.14880 3.74274 33.39157 13.05547 6.70669 9.16730 29.62900 128.36635 18.87201 25.44113 8.84134 21.05356 6.05001 4.01159 53.45878 5.41756 11.52960 4.59985 20.66604 16.10008 11.68180 5.16774 15.63006 27.04703 16.62606 8.09385 30.67252 8.18550 4.82159 3.69058 3.79785 3.50443 4.31370 7.20820 9.20347 4.92465 13.00641 11.28553 83.86455 16.12357 5.37966 9.07668 13.00888 17.09692 15.36582 11.42200 5.86458 16.93136 12.99391 16.69906 12.17518 24.54335 21.63104 12.25514 23.31017 26.92293 15.42681 18.09397 24.81599 17.83970 32.74863 20.95191 8.66831 22.01015 29.33292 26.50901 45.88060 19.35776 17.64418 31.50396 31.62483 29.60532 32.31445 23.79493 27.11842 41.05178 26.55215 22.30262 30.79310 17.33413 26.42663 26.61626 32.10900 35.34843 11.23091 25.10468 21.30500 26.36798 24.04274 15.89093 19.50501 24.87992 39.44589 25.46460 17.33093 23.45218 32.42939 19.71247 15.91531 17.51232 12.86325 30.69141 22.21779 21.68001 10.48244 34.17007 34.81698 29.75594 24.87395 29.43913 32.63330 48.32376 20.38026 28.73485 19.57781 23.99517 2.50355 16.95672 23.49668 45.01190 17.50390 16.92257 26.81689 17.37144 30.98903 23.93275 29.59941 14.31391 51.96381 21.07351 23.74410 14.85903 26.70982 39.16625 16.86057 17.17464 25.98085 25.26771 13.46942 24.39112 36.01778 24.34123 27.43177 23.13213 22.00088 7.17378 20.68588 27.44321 27.80424 65.10874 23.70607 55.69061 38.06824 28.29248 20.70251 20.49361 28.96748 29.74947 33.45116 24.50841 14.27597 14.10644 18.24199 31.85185 29.72375 14.88918 33.80320 18.33175 16.05318 30.78861 30.42650 32.21630 18.88086 25.15962 30.95573 12.53747 30.64970 26.37829 5.81996 0.51051 0.35405 0.39112 1.79240 1.05973 13.72832 0.74570 0.15649 0.58692 0.65086 1.19045 7.01176 0.66373 0.48858 0.51762 0.98461 0.70893 0.61415 1.55158 1.40894 0.45981 0.40927 1.01214 0.60597 0.60665 0.47277 0.86326 1.03080 0.80453 0.61307 0.58082 0.71584 0.86884 0.95799 1.41795 0.74383 0.60042 0.77058 0.52013 1.48379 1.98786 0.54790 0.91281 0.85785 0.52286 0.67866 0.74878 0.86909 0.82789 4.16439 2.15034 0.89349 0.85677 3.61315 1.44175 0.58121 0.33183 0.70069 0.60853 0.52367 1.21831 1.06570 1.04262 0.73462 0.82966 1.72809 0.47109 0.86826 2.42871 0.67586 0.83588 1.42130 0.65770 0.56002 0.75440 1.23118 0.29818 1.02152 3.19776 0.85117 0.53635 1.33859 0.45652 0.57817 0.41834 0.83333 1.27709 0.22914 0.46707 0.48589 0.49237 0.76133 0.51385 0.90869 1.23903 1.33661 0.52042 0.63350 2.30662 0.75823 0.49841 1.59346 0.56226 0.40151 0.82177 1.76283 0.34716 0.77720 0.26545 0.66121 0.67667 0.65163 0.36812 0.81069 0.52844 0.98587 0.67346 1.91364 0.70160 0.39520 0.50087 1.24771 1.34257 0.35976 0.20917 1.90428 1.08322 0.91731 2.07992 4.19479 1.38726 1.69776 2.64082 2.10291 1.75416 1.66766 2.45296 2.50794 2.96405 2.74783 2.30104 4.40048 1.87654 1.28289 1.90280 1.87194 1.28626 1.97504 2.15996 2.40251 3.64395 0.90509 2.25782 1.99335 1.81299 3.99196 2.47965 1.59185 2.77160 2.70382 1.91776 2.00662 2.99867 1.46225 1.89436 2.46865 2.04580 3.84484 3.34232 4.32339 1.48827 2.09341 2.31114 1.98302 3.49174 4.09243 1.32245 2.54044 1.33155 2.66691 3.71614 2.13214 3.36757 2.72235 2.37467 2.35907 2.28413 1.78851 2.30374 2.51652 3.53845 3.90377 1.42840 1.63807 3.64454 2.89872 2.65215 3.87207 2.36248 3.37217 2.14467 4.14468 2.18707 3.58136 1.68956 1.02020 1.71089 1.29550 2.45191 3.67408 3.06837 1.96509 3.06943 2.33487 1.60116 2.48167 1.73375 2.70326 4.36055 3.44288 3.83821 1.97577 4.45906 3.00924 3.55296 4.31691 1.22916 2.15525 3.83804 2.12083 1.88963 3.06893 1.99557 1.73649 3.96781 1.45737 2.56417 1.69132 1.42375 2.11975 1.90499 1.44700 2.24121 2.12867 2.70442 3.88693 1.27723 1.56304 2.20020 2.07363 3.32276 2.79471 1.91105 3.87633 1.60261 2.32017 0.93864 1.05689 1.11657 1.52302 0.73713 0.84764 1.58408 0.07805 0.66380 1.32826 2.36418 0.79295 0.57437 1.53194 0.24234 1.18187 1.08292 0.06759 1.30887 0.25447 0.47249 0.84121 0.82046 0.23122 2.14304 0.44515 1.47068 1.09754 0.46497 0.33129 0.35032 0.43384 0.42950 0.65766 0.26844 0.26706 0.51464 0.82656 2.08697 0.84111 0.80320 1.07799 0.31374 0.58243 2.18495 0.95372 0.88533 0.90071 1.15930 0.47048 0.48927 0.50757 0.89522 0.26940 1.34933 0.37337 0.70234 0.06801 0.27745 1.74369 0.50600 0.44028 0.02881 0.79696 0.24778 1.50668 0.42119 0.04413 0.70788 1.04835 2.12870 0.74264 0.29894 1.08137 0.88078 0.68092 1.98759 0.28475 0.03372 0.26917 0.21331 1.10726 1.06488 0.53571 0.35280 0.52862 1.48189 1.02167 0.11228 0.08531 1.38169 0.62972 1.35856 0.07952 1.34476 0.37993 0.80065 0.10489 1.23058 0.45181 0.88115 0.29322 0.23825 2.03851 0.51294 1.63561 1.09917 0.60881 1.64378 0.10606 1.43607 1.00976 0.63376 0.20283 0.38925 0.08913 0.81041 1.17007 0.91161 0.03660 1.68206 0.17468 0.72902 0.40564 0.05099 0.81769 1.58205 0.21954 
syn_ofm_scale:
24.54335 21.63104 12.25514 23.31017 26.92293 15.42681 18.09397 24.81599 17.83970 32.74863 20.95191 8.66831 22.01015 29.33292 26.50901 45.88060 19.35776 17.64418 31.50396 31.62483 29.60532 32.31445 23.79493 27.11842 41.05178 26.55215 22.30262 30.79310 17.33413 26.42663 26.61626 32.10900 35.34843 11.23091 25.10468 21.30500 26.36798 24.04274 15.89093 19.50501 24.87992 39.44589 25.46460 17.33093 23.45218 32.42939 19.71247 15.91531 17.51232 12.86325 30.69141 22.21779 21.68001 10.48244 34.17007 34.81698 29.75594 24.87395 29.43913 32.63330 48.32376 20.38026 28.73485 19.57781 23.99517 2.50355 16.95672 23.49668 45.01190 17.50390 16.92257 26.81689 17.37144 30.98903 23.93275 29.59941 14.31391 51.96381 21.07351 23.74410 14.85903 26.70982 39.16625 16.86057 17.17464 25.98085 25.26771 13.46942 24.39112 36.01778 24.34123 27.43177 23.13213 22.00088 7.17378 20.68588 27.44321 27.80424 65.10874 23.70607 55.69061 38.06824 28.29248 20.70251 20.49361 28.96748 29.74947 33.45116 24.50841 14.27597 14.10644 18.24199 31.85185 29.72375 14.88918 33.80320 18.33175 16.05318 30.78861 30.42650 32.21630 18.88086 25.15962 30.95573 12.53747 30.64970 26.37829 5.81996 0.51051 0.35405 0.39112 1.79240 1.05973 13.72832 0.74570 0.15649 0.58692 0.65086 1.19045 7.01176 0.66373 0.48858 0.51762 0.98461 0.70893 0.61415 1.55158 1.40894 0.45981 0.40927 1.01214 0.60597 0.60665 0.47277 0.86326 1.03080 0.80453 0.61307 0.58082 0.71584 0.86884 0.95799 1.41795 0.74383 0.60042 0.77058 0.52013 1.48379 1.98786 0.54790 0.91281 0.85785 0.52286 0.67866 0.74878 0.86909 0.82789 4.16439 2.15034 0.89349 0.85677 3.61315 1.44175 0.58121 0.33183 0.70069 0.60853 0.52367 1.21831 1.06570 1.04262 0.73462 0.82966 1.72809 0.47109 0.86826 2.42871 0.67586 0.83588 1.42130 0.65770 0.56002 0.75440 1.23118 0.29818 1.02152 3.19776 0.85117 0.53635 1.33859 0.45652 0.57817 0.41834 0.83333 1.27709 0.22914 0.46707 0.48589 0.49237 0.76133 0.51385 0.90869 1.23903 1.33661 0.52042 0.63350 2.30662 0.75823 0.49841 1.59346 0.56226 0.40151 0.82177 1.76283 0.34716 0.77720 0.26545 0.66121 0.67667 0.65163 0.36812 0.81069 0.52844 0.98587 0.67346 1.91364 0.70160 0.39520 0.50087 1.24771 1.34257 0.35976 0.20917 1.90428 1.08322 0.91731 2.07992 4.19479 1.38726 1.69776 2.64082 2.10291 1.75416 1.66766 2.45296 2.50794 2.96405 2.74783 2.30104 4.40048 1.87654 1.28289 1.90280 1.87194 1.28626 1.97504 2.15996 2.40251 3.64395 0.90509 2.25782 1.99335 1.81299 3.99196 2.47965 1.59185 2.77160 2.70382 1.91776 2.00662 2.99867 1.46225 1.89436 2.46865 2.04580 3.84484 3.34232 4.32339 1.48827 2.09341 2.31114 1.98302 3.49174 4.09243 1.32245 2.54044 1.33155 2.66691 3.71614 2.13214 3.36757 2.72235 2.37467 2.35907 2.28413 1.78851 2.30374 2.51652 3.53845 3.90377 1.42840 1.63807 3.64454 2.89872 2.65215 3.87207 2.36248 3.37217 2.14467 4.14468 2.18707 3.58136 1.68956 1.02020 1.71089 1.29550 2.45191 3.67408 3.06837 1.96509 3.06943 2.33487 1.60116 2.48167 1.73375 2.70326 4.36055 3.44288 3.83821 1.97577 4.45906 3.00924 3.55296 4.31691 1.22916 2.15525 3.83804 2.12083 1.88963 3.06893 1.99557 1.73649 3.96781 1.45737 2.56417 1.69132 1.42375 2.11975 1.90499 1.44700 2.24121 2.12867 2.70442 3.88693 1.27723 1.56304 2.20020 2.07363 3.32276 2.79471 1.91105 3.87633 1.60261 2.32017 0.93864 1.05689 1.11657 1.52302 0.73713 0.84764 1.58408 0.07805 0.66380 1.32826 2.36418 0.79295 0.57437 1.53194 0.24234 1.18187 1.08292 0.06759 1.30887 0.25447 0.47249 0.84121 0.82046 0.23122 2.14304 0.44515 1.47068 1.09754 0.46497 0.33129 0.35032 0.43384 0.42950 0.65766 0.26844 0.26706 0.51464 0.82656 2.08697 0.84111 0.80320 1.07799 0.31374 0.58243 2.18495 0.95372 0.88533 0.90071 1.15930 0.47048 0.48927 0.50757 0.89522 0.26940 1.34933 0.37337 0.70234 0.06801 0.27745 1.74369 0.50600 0.44028 0.02881 0.79696 0.24778 1.50668 0.42119 0.04413 0.70788 1.04835 2.12870 0.74264 0.29894 1.08137 0.88078 0.68092 1.98759 0.28475 0.03372 0.26917 0.21331 1.10726 1.06488 0.53571 0.35280 0.52862 1.48189 1.02167 0.11228 0.08531 1.38169 0.62972 1.35856 0.07952 1.34476 0.37993 0.80065 0.10489 1.23058 0.45181 0.88115 0.29322 0.23825 2.03851 0.51294 1.63561 1.09917 0.60881 1.64378 0.10606 1.43607 1.00976 0.63376 0.20283 0.38925 0.08913 0.81041 1.17007 0.91161 0.03660 1.68206 0.17468 0.72902 0.40564 0.05099 0.81769 1.58205 0.21954 1.15577 1.04414 1.00791 0.00000 0.00000 0.00000 0.00000 0.00000 
save_png(s): 0.92912
syn_output: recon_c.png, h_w_c= [1365, 2048, 3]

X-LIC/sw_sim$ make gen_reorder_w_sk_i16c_scale
g++ -O3 -w -o test_reorder weight_reorder_sk_i16c_scale.cpp -I . -lm
./test_reorder  8 8 64
Layer[x]; param num=       31104 sum2_error = 0.9448845,min_error=0.0000000,max_error=0.0000610,add_offset = 0
ana_kernel_scale[layer 0]: 128
0.225055 0.237296 0.373880 0.260098 0.531330 0.165818 0.148947 0.445908 0.170151 0.200833 0.167590 0.182580 0.199225 0.980556 0.510683 0.448036 0.111066 0.631133 0.186018 0.189641 0.142772 0.192934 0.438250 0.520388 0.210549 0.177195 0.280721 0.176198 0.205126 0.661552 0.510595 0.436457 0.204955 0.361915 0.234862 0.191611 0.427454 0.611326 0.190420 0.228873 1.141163 0.877437 0.396672 0.255384 0.729060 0.198744 0.169571 0.160956 0.246616 0.540760 0.155805 0.225777 0.293986 0.567261 0.392496 0.216836 0.204307 0.827114 0.201451 0.228318 0.525964 0.518119 0.229340 0.217786 0.178666 0.510584 0.236121 0.210427 0.303614 0.167409 0.112202 0.202841 0.180769 0.183855 0.218421 0.500220 0.262842 0.206621 0.615586 0.208496 0.126984 0.190780 0.301233 0.473933 0.278001 0.749024 0.463060 0.625574 0.822353 0.186323 0.138109 0.254235 0.242063 0.558940 0.693118 0.167648 0.491871 0.200210 0.200082 0.198618 0.184500 0.676253 0.177592 0.605657 0.581336 0.528060 0.278074 0.200355 0.161340 0.724994 0.862936 0.318258 0.213048 0.210001 0.758210 0.270510 0.195200 0.277854 0.196408 0.220545 0.675083 0.509716 0.286615 0.206250 0.149472 0.236433 0.148629 0.443114 
Layer[x]; param num=       16384 sum2_error = 0.1091819,min_error=0.0000000,max_error=0.0000610,add_offset = 0
ana_kernel_scale[layer 1]: 128
0.031147 0.000994 0.917249 0.064610 1.773192 0.006014 0.000022 1.083094 0.027781 0.017409 0.069763 0.021264 0.000020 2.591479 0.052098 1.825990 0.028488 4.148032 0.086192 0.092456 0.003413 0.031486 1.499829 2.352924 0.009111 0.031125 0.032819 0.322771 1.284640 2.922270 1.834260 0.123121 0.000009 0.238006 0.000017 0.000012 2.934916 1.586229 0.021563 0.158086 3.503239 2.969779 0.999871 1.739478 1.430983 0.010429 0.000091 0.017507 0.031142 2.291910 0.000352 0.000980 2.745074 1.641775 2.835114 0.042163 0.087813 3.191728 0.028445 0.000010 4.292156 2.081964 0.021621 4.193572 0.000005 0.531968 0.032499 0.041076 0.001190 0.085120 0.204190 0.006309 0.082815 0.002656 0.021245 2.972432 0.037492 0.007545 2.118101 0.034720 0.250841 0.267169 0.056243 1.415591 0.393664 2.807176 2.457098 2.574513 2.458302 0.012572 0.000010 0.594831 0.062328 2.507060 3.400230 0.113844 3.607721 0.016259 0.001798 0.060283 0.033855 2.920895 0.023380 1.751863 3.301947 3.775176 0.031130 0.245461 0.543633 1.629322 3.574587 1.310744 0.000016 0.005284 2.417200 0.030942 0.098967 0.660635 0.000019 0.233566 2.263718 2.047902 0.083831 0.016424 0.005144 0.346454 0.209380 1.929998 
Layer[x]; param num=      409600 sum2_error = 12.5154430,min_error=0.0000000,max_error=0.0000610,add_offset = 0
ana_kernel_scale[layer 2]: 128
1.041856 0.641916 0.462146 0.387104 0.606160 0.493124 0.497160 0.478551 0.419493 0.548309 0.854383 0.458903 0.462944 0.602404 0.478335 0.474708 0.496113 0.647565 0.624261 1.069949 0.441687 0.860811 0.390646 0.529091 0.378573 0.486991 0.672581 0.525961 0.727371 0.441628 0.529915 0.846093 0.528079 0.576039 0.317257 0.543614 1.090287 0.515437 0.476315 0.493445 0.683831 0.587894 0.972766 0.632019 0.488754 0.540586 0.453084 0.737196 0.682935 0.359626 0.552318 0.821144 0.535776 0.756995 0.432804 0.520991 0.504678 0.338343 0.382012 0.446501 0.496451 0.346181 0.636842 0.628777 0.412958 0.488068 0.531319 0.545944 0.405578 0.336560 0.694092 0.445187 0.536115 0.559032 0.510096 0.802232 0.634371 0.400471 0.588955 0.399064 0.656833 0.440687 0.461172 0.738143 0.480313 0.679742 0.678318 0.549839 0.550081 0.436790 0.546642 0.827783 1.101233 0.425219 0.443169 0.399670 0.484448 0.565104 0.513691 0.394630 0.536995 0.448727 0.438991 0.421724 0.366782 0.439024 0.404632 0.588932 0.326572 0.413965 0.432353 0.503120 0.492383 0.509755 0.398704 0.251750 0.658331 0.714396 0.381841 0.354799 0.671605 0.284033 0.561109 0.620649 0.486757 0.606509 0.646353 0.356007 
Layer[x]; param num=       16384 sum2_error = 0.1628420,min_error=0.0000000,max_error=0.0000610,add_offset = 0
ana_kernel_scale[layer 3]: 128
0.046144 0.730936 0.404517 0.016251 0.050200 0.478955 0.002989 0.101177 0.244274 0.063992 0.104361 0.005713 0.003666 0.715628 0.001737 1.003897 1.846146 0.003832 0.001185 1.032861 0.002879 0.123857 0.010689 0.784684 0.138518 0.227651 0.004473 0.787519 0.034952 0.542330 0.034728 0.021779 0.010181 0.005315 0.029316 0.005677 0.011603 0.011323 0.000020 0.393513 0.824758 0.008231 0.002459 0.008508 0.006151 0.003856 1.059540 0.068721 0.001846 0.222806 0.922524 0.074067 0.344694 0.071218 0.093439 0.746680 0.002819 0.135685 0.019124 0.008044 0.061544 0.189933 0.993708 0.980550 0.325430 0.014055 0.004233 0.021040 0.632051 0.629886 0.012413 3.369976 0.543556 1.082365 2.283820 0.065866 0.022350 2.036104 0.057355 0.011776 1.624132 0.031070 1.855072 0.006051 0.097436 0.020411 0.014552 0.018227 0.002596 0.001815 0.013970 0.148585 0.121497 0.006129 0.007664 0.016338 3.653622 0.080070 1.272480 0.010641 1.848974 0.017837 0.096603 0.072445 0.084457 0.999178 0.871463 0.005900 1.161402 0.001662 0.012083 0.000023 0.000016 0.996533 0.007326 0.000017 1.173588 1.121154 0.468973 0.031208 0.116281 0.022956 1.572613 1.557843 0.784756 2.276247 0.422096 0.037217 
Layer[x]; param num=      409600 sum2_error = 12.4671503,min_error=0.0000000,max_error=0.0000610,add_offset = 0
ana_kernel_scale[layer 4]: 128
2.923946 10.322406 8.680380 5.039128 5.954483 2.491461 3.205050 4.837364 1.746119 5.175746 1.999217 2.837621 3.499777 3.577027 4.925703 2.505244 2.450546 2.320180 3.821878 1.722579 1.946533 3.634373 2.370607 4.615683 2.524273 2.184776 2.447839 2.107969 2.084081 7.890220 3.272768 3.880426 3.963904 6.020606 3.098921 3.629712 1.863827 3.055016 1.989012 2.183815 4.395059 2.075487 5.750112 4.415493 2.057778 8.084855 2.268885 1.731475 1.715138 6.948359 5.662017 1.711247 3.313944 2.379231 3.957417 3.599319 2.848652 4.356259 1.812490 3.926514 2.229153 2.246058 5.405558 6.886425 2.151323 1.910338 3.327308 5.429874 8.585103 1.472741 5.870683 5.475684 2.628092 3.802092 1.476167 8.759883 9.216216 2.747183 2.918596 6.905809 3.743460 4.403010 4.984286 8.193431 8.215318 10.167223 6.264434 5.028945 6.275968 2.087775 2.172396 5.412048 2.777023 4.552152 2.145208 3.387579 3.470743 5.573725 4.177907 4.391067 7.409706 7.635390 3.045193 4.687135 2.862561 1.929939 1.387904 2.272587 2.108236 2.025977 2.828317 5.276392 3.089357 3.308065 4.800058 4.949316 4.758604 1.643609 3.413961 4.123566 4.512076 4.838840 4.182240 1.986061 7.167816 6.782355 4.270785 4.644061 
Layer  0;param num=         128 
Layer  1;param num=         128 
Layer  2;param num=         128 
Layer  3;param num=         128 
Layer[x]; param num=      409600 sum2_error = 12.4796037,min_error=0.0000000,max_error=0.0000610,add_offset = 0
syn_kernel_scale[layer 0]: 128
10.545934 11.220608 5.894372 18.580225 14.172848 11.742648 7.934351 12.472862 6.512974 13.509352 8.844347 6.992038 12.429921 18.781952 13.033722 30.294296 7.284652 10.943565 15.761856 14.158021 17.108736 14.108109 11.591042 11.415378 22.665096 12.057082 9.858664 14.682076 7.709924 8.873487 15.681154 17.452759 14.292474 6.232165 21.032572 9.383433 14.467845 10.266365 9.838014 7.334391 15.940617 22.200485 9.428763 8.945143 16.157557 12.416564 6.446593 18.214333 9.009157 12.767481 18.291157 10.684914 13.816287 7.894397 22.787989 17.037916 19.558895 11.996464 10.575623 12.314745 32.737629 8.125492 10.924118 7.638799 14.659725 0.882190 10.556087 13.712626 24.636131 13.059223 8.920826 15.610270 9.695520 17.147835 10.328279 18.219175 5.936820 40.411011 13.003512 13.561676 6.645669 22.867477 19.490736 8.109791 7.789051 19.293327 13.395109 5.476264 7.637262 27.406006 9.696425 11.105989 11.004747 11.826962 3.829394 11.489026 12.876167 13.075477 30.856312 10.341286 37.469288 18.538826 11.943660 6.944188 9.471856 23.288944 15.449796 21.577160 8.422316 7.292051 6.076042 5.177769 12.419399 12.442941 6.609837 18.593575 14.085272 13.049466 13.537673 27.681000 19.115765 11.402278 13.528374 20.143761 5.650653 18.339474 14.503698 3.841491 
Layer[x]; param num=       16384 sum2_error = 0.3922031,min_error=0.0000000,max_error=0.0000610,add_offset = 0
syn_kernel_scale[layer 1]: 128
0.000476 0.000713 0.000252 0.064226 0.000376 0.000370 0.001189 0.006625 0.001067 0.000283 0.000675 0.000062 0.000887 0.018685 0.000149 0.009670 0.002108 0.013942 0.000299 0.000809 0.000166 0.000261 0.018114 0.000224 0.000255 0.000478 0.001574 0.000847 0.002369 0.000390 0.000132 0.009570 0.012053 0.001160 0.000515 0.000544 0.000698 0.000886 0.001175 0.094045 0.001223 0.000102 0.000394 0.001446 0.000247 0.000265 0.000589 0.018064 0.000710 0.001508 0.000678 0.000647 0.000742 0.153771 0.016105 0.000323 0.000187 0.000582 0.009158 0.000259 0.017845 0.013175 0.000776 0.000390 0.022896 0.000372 0.002546 0.000774 0.000511 0.001234 0.001531 0.000382 0.000444 0.001417 0.000786 0.000201 0.000200 0.021519 0.001592 0.000912 0.001407 0.000402 0.000436 0.001796 0.000198 0.000205 0.000777 0.002015 0.000619 0.004966 0.000279 0.000189 0.000945 0.015481 0.011786 0.032796 0.000299 0.000252 0.011747 0.000261 0.000112 0.001010 0.011096 0.003276 0.000333 0.000312 0.000451 0.000305 0.001117 0.002457 0.013868 0.001101 0.000183 0.000176 0.037529 0.000259 0.011110 0.098929 0.000293 0.000229 0.000375 0.040527 0.020167 0.000276 0.016666 0.000336 0.000786 0.006723 
Layer[x]; param num=      409600 sum2_error = 12.5022823,min_error=0.0000000,max_error=0.0000610,add_offset = 0
syn_kernel_scale[layer 2]: 128
0.581394 0.952564 1.151049 0.739275 0.836730 0.912252 1.152375 0.806738 0.982263 1.027219 1.399865 1.934632 1.337994 1.599005 0.579546 1.009803 1.993251 2.043402 0.894019 0.744953 1.237016 0.564994 0.780739 0.514860 1.463014 0.559413 1.172089 0.911584 1.219949 2.143979 1.114082 1.152261 0.694948 0.553035 0.984977 0.542212 1.175235 0.442300 1.253924 1.159255 0.999771 1.846647 0.478693 1.090202 1.732434 1.157109 1.127013 0.911473 0.754867 1.045734 1.166233 0.814643 0.957714 0.692576 0.525165 1.172486 0.572739 1.345894 1.027143 1.168101 0.543036 1.044394 1.078660 0.953465 0.495688 1.159569 1.052434 1.375249 0.936337 0.794160 1.352141 0.884565 0.607124 1.797092 0.597948 0.962274 1.075469 0.610868 1.375628 0.545391 2.243261 1.054031 1.685254 0.458112 0.778800 0.839176 0.975596 0.601524 1.013996 1.095381 1.198881 0.802404 0.991223 0.727996 1.036959 0.937216 0.732550 2.133775 0.961071 1.181018 0.879552 0.537071 0.996910 2.709049 0.476939 1.746621 0.893342 0.528994 0.721539 0.744787 0.825952 0.921037 0.523053 1.072109 1.513179 1.486976 1.068514 0.830430 0.900324 0.633303 1.489267 0.456821 1.073372 1.111975 1.651283 0.864435 0.854374 1.265861 
Layer[x]; param num=       16384 sum2_error = 0.2221418,min_error=0.0000000,max_error=0.0000610,add_offset = 0
syn_kernel_scale[layer 3]: 128
0.156208 0.060915 0.013454 0.001756 0.155528 0.453053 0.015216 0.035856 0.143984 0.013334 0.015107 0.013364 0.285260 0.171145 0.072585 0.004814 0.012324 0.015375 0.043593 0.065906 0.131536 0.264501 0.054059 0.051011 0.041618 0.072341 0.016641 0.061614 0.220682 0.006836 0.162004 0.068616 0.313302 0.174545 0.082594 0.052572 0.218042 0.184946 0.035594 0.081188 0.082067 0.063340 0.115552 0.276228 0.010048 0.114067 0.129330 0.059430 0.018542 0.097799 0.063218 0.051858 0.050759 0.043034 0.213324 0.109717 0.119590 0.019549 0.060186 0.005751 0.077433 0.078357 0.014404 0.070622 0.076817 0.021503 0.069742 0.018564 0.075691 0.059881 0.000463 0.057254 0.054753 0.195211 0.226450 0.118517 0.202369 0.304747 0.018636 0.081465 0.023909 0.128670 0.219400 0.098644 0.047941 0.263975 0.022055 0.283439 0.024324 0.012187 0.121599 0.068218 0.128784 0.022709 0.072857 0.046966 0.058925 0.009351 0.055813 0.288701 0.051927 0.058695 0.096938 0.003626 0.140377 0.022198 0.068178 0.144276 0.303494 0.021850 0.040631 0.293260 0.113479 0.124060 0.009813 0.014846 0.125859 0.060690 0.009304 0.018345 0.009058 0.029808 0.052498 0.090598 0.002679 0.064159 0.012586 0.049156 
Layer[x]; param num=       31104 sum2_error = 0.9488423,min_error=0.0000000,max_error=0.0000610,add_offset = 51840
syn_kernel_scale[layer 4]: 3
0.439908 0.449402 0.430605 
Layer  0;param num=         128 
Layer  1;param num=         128 
Layer  2;param num=         128 
Layer  3;param num=         128 
Layer  4;param num=           3 add 5

X-LIC/sw_sim$ make test_iofm_reorder_w_sk_i16c
g++ -O3 -w -o test_ana main_ana_chw_rsc_0_2.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
g++ -O3 -w -o test_syn main_syn_chw_rsc_0_2.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
./test_ana ../img/abigail-keenan-27293.png
Input img:../img/abigail-keenan-27293.png
 w=2048,h=1365,c=3
ana_kernel_w_i16rc.bin's data size is 1766144
read weight byte_num = 441536
ana_bias_f32c.bin's data size is 2048
512
read bias byte_num = 2048
5
5
ana_0: ic_h_w= [3, 1365, 2048], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 11.95581
gdn_0: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 2.61340
ana_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 14.48133
gdn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 0.66240
ana_2: ic_h_w= [128, 171, 256], oc_h_w= [128, 86, 128], w_aoffset=0, bias_aoffset=0, lat= 3.63348
ana_output: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
./test_syn ana_q_out_chw.bin ana_IHW_OHW_set.bin
ana_IHW_OHW_set.bin's data size is 80
fm_max_size_calc = 44826624
syn_kernel_w_T_i16rc.bin's data size is 1869824
read weight byte_num = 467456
syn_bias_f32c.bin's data size is 2080
520
read bias byte_num = 2080
5
5
syn_input: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
syn_0: ic_h_w= [128, 86, 128], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 3.65672
igdn_0: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 0.67346
syn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 14.60497
igdn_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 2.70002
syn_2: ic_h_w= [128, 342, 512], oc_h_w= [3, 1365, 2048], w_aoffset=51840, bias_aoffset=5, lat= 95.04695
save_png(s): 0.94935
syn_output: recon_c.png, h_w_c= [1365, 2048, 3]

X-LIC/sw_sim$ make gen_interQ_sk_i16c
g++ -O3 -w -o test_ana main_ana_chw_rsc_0_3.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
g++ -O3 -w -o test_syn main_syn_chw_rsc_0_3.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
./test_ana ../img/abigail-keenan-27293.png
Input img:../img/abigail-keenan-27293.png
 w=2048,h=1365,c=3
ana_kernel_w_i16rc.bin's data size is 1766144
read weight byte_num = 441536
ana_bias_f32c.bin's data size is 2048
512
read bias byte_num = 2048
5
5
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0005493164, diff sum = 698.9813843
[2]: diff max= 0.0009765625, diff sum = 1681.5447998
[3]: diff max= 0.0021972656, diff sum = 3626.6309204
[4]: diff max= 0.0050659180, diff sum = 7568.9780273
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 2.0399169922, diff sum = 128657.1503296
[1]: diff max= 1.8579101562, diff sum = 881.3211060
[2]: diff max= 0.0000610352, diff sum = 5.2509155
[3]: diff max= 0.0000610352, diff sum = 14.0045166
[4]: diff max= 0.0000610352, diff sum = 32.8590088
[5]: diff max= 0.0000610352, diff sum = 71.7180176
[6]: diff max= 0.0000610352, diff sum = 150.3399658
[Q=2]: diff max= 0.0000610352, diff sum_min = 5.2509155
ana_0: ic_h_w= [3, 1365, 2048], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 368.38460
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0008544922, diff sum = 278.6452026
[2]: diff max= 0.0018920898, diff sum = 835.9694214
[3]: diff max= 0.0045776367, diff sum = 1951.8322144
[4]: diff max= 0.0097045898, diff sum = 4184.6965942
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 0.0000610352, diff sum = 0.0320435
[1]: diff max= 0.0000610352, diff sum = 0.0587769
[2]: diff max= 0.0000610352, diff sum = 0.2025757
[3]: diff max= 0.0000610352, diff sum = 0.5545044
[4]: diff max= 0.0000610352, diff sum = 1.3073120
[Q=0]: diff max= 0.0000610352, diff sum_min = 0.0320435
gdn_0: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 74.02856
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0006103516, diff sum = 199.6190796
[2]: diff max= 0.0014648438, diff sum = 498.6394043
[3]: diff max= 0.0029907227, diff sum = 1088.1786499
[4]: diff max= 0.0070800781, diff sum = 2263.8557739
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 2.0097656250, diff sum = 226556.3305664
[1]: diff max= 1.9299926758, diff sum = 32097.9645996
[2]: diff max= 0.0000610352, diff sum = 11.5545044
[3]: diff max= 0.0000610352, diff sum = 31.6536865
[4]: diff max= 0.0000610352, diff sum = 74.7495728
[5]: diff max= 0.0001220703, diff sum = 163.7145996
[6]: diff max= 0.0002441406, diff sum = 344.7271729
[Q=2]: diff max= 0.0000610352, diff sum_min = 11.5545044
ana_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 431.24451
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0003662109, diff sum = 37.6287842
[2]: diff max= 0.0009765625, diff sum = 112.9432983
[3]: diff max= 0.0020751953, diff sum = 263.5299683
[4]: diff max= 0.0045776367, diff sum = 565.2826538
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 0.0000610352, diff sum = 0.0070801
[1]: diff max= 0.0000610352, diff sum = 0.0090332
[2]: diff max= 0.0000610352, diff sum = 0.0249634
[3]: diff max= 0.0000610352, diff sum = 0.0661621
[4]: diff max= 0.0000610352, diff sum = 0.1656494
[Q=0]: diff max= 0.0000610352, diff sum_min = 0.0070801
gdn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 18.54903
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0004272461, diff sum = 57.2335205
[2]: diff max= 0.0010986328, diff sum = 142.0036011
[3]: diff max= 0.0022583008, diff sum = 308.8721313
[4]: diff max= 0.0042724609, diff sum = 640.6303711
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 1.8496704102, diff sum = 3372.7151489
[1]: diff max= 1.8884277344, diff sum = 3428.9366455
[2]: diff max= 0.0000610352, diff sum = 5.9623413
[3]: diff max= 0.0000610352, diff sum = 16.4709473
[4]: diff max= 0.0001220703, diff sum = 38.8663330
[5]: diff max= 0.0001831055, diff sum = 85.1210938
[Q=2]: diff max= 0.0000610352, diff sum_min = 5.9623413
ana_2: ic_h_w= [128, 171, 256], oc_h_w= [128, 86, 128], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 98.66493
ana_output: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
./test_syn ana_q_out_chw.bin ana_IHW_OHW_set.bin
ana_IHW_OHW_set.bin's data size is 80
fm_max_size_calc = 44826624
syn_kernel_w_T_i16rc.bin's data size is 1869824
read weight byte_num = 467456
syn_bias_f32c.bin's data size is 2080
520
read bias byte_num = 2080
5
5
syn_input: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0003051758, diff sum = 222.2032471
[2]: diff max= 0.0007324219, diff sum = 585.6014404
[3]: diff max= 0.0015869141, diff sum = 1308.3878174
[4]: diff max= 0.0033569336, diff sum = 2746.6947021
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 0.0000610352, diff sum = 0.3058472
[1]: diff max= 0.0000610352, diff sum = 2.2216187
[2]: diff max= 0.0000610352, diff sum = 8.8909302
[3]: diff max= 0.0000610352, diff sum = 24.4157104
[4]: diff max= 0.0000610352, diff sum = 57.8325195
[Q=0]: diff max= 0.0000610352, diff sum_min = 0.3058472
syn_0: ic_h_w= [128, 86, 128], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 88.04248
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0002441406, diff sum = 24.1046143
[2]: diff max= 0.0006103516, diff sum = 72.2500000
[3]: diff max= 0.0014038086, diff sum = 168.5154419
[4]: diff max= 0.0030517578, diff sum = 360.7451782
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 1.5436401367, diff sum = 4.1611328
[1]: diff max= 0.0000610352, diff sum = 0.0125122
[2]: diff max= 0.0000610352, diff sum = 0.0362549
[3]: diff max= 0.0000610352, diff sum = 0.0939941
[4]: diff max= 0.0000610352, diff sum = 0.2243042
[5]: diff max= 0.0000610352, diff sum = 0.4747314
[Q=1]: diff max= 0.0000610352, diff sum_min = 0.0125122
igdn_0: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 20.25922
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0003662109, diff sum = 752.3333740
[2]: diff max= 0.0009155273, diff sum = 1993.3098145
[3]: diff max= 0.0019531250, diff sum = 4455.6995239
[4]: diff max= 0.0040893555, diff sum = 9373.9097900
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 0.0000610352, diff sum = 1.2369385
[1]: diff max= 0.0000610352, diff sum = 7.6309814
[2]: diff max= 0.0000610352, diff sum = 30.2238159
[3]: diff max= 0.0000610352, diff sum = 83.1235352
[4]: diff max= 0.0000610352, diff sum = 196.3587036
[Q=0]: diff max= 0.0000610352, diff sum_min = 1.2369385
syn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 352.03317
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0002441406, diff sum = 128.9521484
[2]: diff max= 0.0006713867, diff sum = 387.1781006
[3]: diff max= 0.0014038086, diff sum = 903.1717529
[4]: diff max= 0.0031127930, diff sum = 1934.1359253
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 0.0000610352, diff sum = 0.0343018
[1]: diff max= 0.0000610352, diff sum = 0.0425415
[2]: diff max= 0.0000610352, diff sum = 0.1174316
[3]: diff max= 0.0000610352, diff sum = 0.3207397
[4]: diff max= 0.0000610352, diff sum = 0.7469482
[Q=0]: diff max= 0.0000610352, diff sum_min = 0.0343018
igdn_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 74.02310
[0]: diff max= 0.0000000000, diff sum = 0.0000000
[1]: diff max= 0.0001831055, diff sum = 88.9296875
[2]: diff max= 0.0004272461, diff sum = 229.4660034
[3]: diff max= 0.0009155273, diff sum = 507.8545532
[4]: diff max= 0.0020141602, diff sum = 1064.4729614
[Q=0]: diff max= 0.0000000000, diff sum_min = 0.0000000
maxQ = 28
[0]: diff max= 0.0000610352, diff sum = 0.4697266
[1]: diff max= 0.0000610352, diff sum = 0.8714600
[2]: diff max= 0.0000610352, diff sum = 3.0908203
[3]: diff max= 0.0000610352, diff sum = 8.4802246
[4]: diff max= 0.0000610352, diff sum = 20.0704346
[Q=0]: diff max= 0.0000610352, diff sum_min = 0.4697266
syn_2: ic_h_w= [128, 342, 512], oc_h_w= [3, 1365, 2048], w_aoffset=51840, bias_aoffset=5, lat= 2203.82901
save_png(s): 0.95702
syn_output: recon_c.png, h_w_c= [1365, 2048, 3]

X-LIC/sw_sim$ make test_interQ_sk_i16c
g++ -O3 -w -o test_ana main_ana_chw_rsc_0_4.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
g++ -O3 -w -o test_syn main_syn_chw_rsc_0_4.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
./test_ana ../img/abigail-keenan-27293.png
Input img:../img/abigail-keenan-27293.png
 w=2048,h=1365,c=3
ana_kernel_w_i16rc.bin's data size is 1766144
read weight byte_num = 441536
ana_bias_f32c.bin's data size is 2048
512
read bias byte_num = 2048
5
5
TR,TC,TM,TN, interQ=1,282,64,3
ana_0: ic_h_w= [3, 1365, 2048], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 9.00673
TR,TC,TM,TN, interQ=1,512,64,8
gdn_0: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 1.85773
TR,TC,TM,TN, interQ=2,256,64,8
ana_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 10.99466
TR,TC,TM,TN, interQ=2,256,64,8
gdn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 0.46408
TR,TC,TM,TN, interQ=4,128,64,8
ana_2: ic_h_w= [128, 171, 256], oc_h_w= [128, 86, 128], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 2.75237
ana_output: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
./test_syn ana_q_out_chw.bin ana_IHW_OHW_set.bin
ana_IHW_OHW_set.bin's data size is 80
fm_max_size_calc = 44826624
syn_kernel_w_T_i16rc.bin's data size is 1869824
read weight byte_num = 467456
syn_bias_f32c.bin's data size is 2080
520
read bias byte_num = 2080
5
5
syn_input: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
TR,TC,TM,TN, interQ=2,256,64,8
syn_0: ic_h_w= [128, 86, 128], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 2.76675
TR,TC,TM,TN, interQ=2,256,64,8
igdn_0: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 0.46932
TR,TC,TM,TN, interQ=2,288,64,8
syn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 11.03830
TR,TC,TM,TN, interQ=1,512,64,8
igdn_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 1.87812
TR,TC,TM,TN, interQ=4,144,3,8
syn_2: ic_h_w= [128, 342, 512], oc_h_w= [3, 1365, 2048], w_aoffset=51840, bias_aoffset=5, lat= 71.24717
save_png(s): 0.97795
syn_output: recon_c.png, h_w_c= [1365, 2048, 3]

X-LIC/sw_sim$ make test_interQ_sk_i16c_sr_cb 
g++ -O3 -w -o test_ana main_ana_chw_rsc_0_4_srcb.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
g++ -O3 -w -o test_syn main_syn_chw_rsc_0_4_srcb.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
./test_ana ../img/abigail-keenan-27293.png
Input img:../img/abigail-keenan-27293.png
 w=2048,h=1365,c=3
ana_kernel_w_i16rc.bin's data size is 1766144
read weight byte_num = 441536
ana_bias_f32c.bin's data size is 2048
512
read bias byte_num = 2048
5
5
TR,TC,TM,TN, interQ=1,282,64,3
ana_0: ic_h_w= [3, 1365, 2048], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 8.96579
TR,TC,TM,TN, interQ=1,512,64,8
gdn_0: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 1.85771
TR,TC,TM,TN, interQ=2,256,64,8
ana_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 10.89454
TR,TC,TM,TN, interQ=2,256,64,8
gdn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 0.46467
TR,TC,TM,TN, interQ=4,128,64,8
ana_2: ic_h_w= [128, 171, 256], oc_h_w= [128, 86, 128], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 2.73522
ana_output: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
ana_kernel_w_i16rc.bin's data size is 1766144
./test_syn ana_q_out_chw.bin ana_IHW_OHW_set.bin
ana_IHW_OHW_set.bin's data size is 80
fm_max_size_calc = 44826624
syn_kernel_w_T_i16rc.bin's data size is 1869824
read weight byte_num = 467456
syn_bias_f32c.bin's data size is 2080
520
read bias byte_num = 2080
5
5
syn_input: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
TR,TC,TM,TN, interQ=2,256,64,8
syn_0: ic_h_w= [128, 86, 128], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 2.76294
TR,TC,TM,TN, interQ=2,256,64,8
igdn_0: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 0.47058
TR,TC,TM,TN, interQ=2,288,64,8
syn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 11.03346
TR,TC,TM,TN, interQ=1,512,64,8
igdn_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 1.88281
TR,TC,TM,TN, interQ=4,144,3,8
syn_2: ic_h_w= [128, 342, 512], oc_h_w= [3, 1365, 2048], w_aoffset=51840, bias_aoffset=5, lat= 71.29414
save_png(s): 0.94536
syn_output: recon_c.png, h_w_c= [1365, 2048, 3]
syn_kernel_w_T_i16rc.bin's data size is 1869824

X-LIC/sw_sim$ make test_as_rsc_i16c_NTP 
g++ -O3 -w -o test_ana main_ana_chw_rsc_0_4_NTP.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
g++ -O3 -w -o test_syn main_syn_chw_rsc_0_4_NTP.cpp -I . -lm -D MAX_Pif=4 -D MAX_Pof=64 -D MAX_Poy=1 -D MAX_Pox=2 -D MAX_S=4 -D MAX_K=9 -D MAX_Tif=8 -D MAX_Tof=64 -D MAX_Tr=24 -D MAX_Tc=24 -D MAX_BETA_LENGTH=128 -D LANE_NUM=8 -D _DEF_IN_MAKEFILE_
./test_ana ../img/abigail-keenan-27293.png
Input img:../img/abigail-keenan-27293.png
 w=2048,h=1365,c=3
ana_kernel_w_i16rc_srcb.bin's data size is 1766144
read weight byte_num = 441536
ana_bias_f32c.bin's data size is 2048
512
read bias byte_num = 2048
5
5
TR,TC,TM,TN=1,26,64,3
ana_0: ic_h_w= [3, 1365, 2048], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 30.13661
TR,TC,TM,TN=2,512,64,8
gdn_0: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 11.59544
TR,TC,TM,TN=1,100,64,8
ana_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 70.02840
TR,TC,TM,TN=4,256,64,8
gdn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=0, lat= 2.92429
TR,TC,TM,TN=1,100,64,8
ana_2: ic_h_w= [128, 171, 256], oc_h_w= [128, 86, 128], w_aoffset=0, bias_aoffset=0, ifm_sqQ=0, interQ=2, lat= 17.89261
ana_output: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
./test_syn ana_q_out_chw.bin ana_IHW_OHW_set.bin
ana_IHW_OHW_set.bin's data size is 80
fm_max_size_calc = 44826624
syn_kernel_w_T_i16rc_srcb.bin's data size is 1869824
read weight byte_num = 467456
syn_bias_f32c.bin's data size is 2080
520
read bias byte_num = 2080
5
5
syn_input: ana_q_out_chw.bin, h_w_c= [86, 128, 128]
TR,TC,TM,TN=2,164,64,8
syn_0: ic_h_w= [128, 86, 128], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 18.34966
TR,TC,TM,TN=4,256,64,8
igdn_0: ic_h_w= [128, 171, 256], oc_h_w= [128, 171, 256], w_aoffset=0, bias_aoffset=0, lat= 2.96785
TR,TC,TM,TN=2,164,64,8
syn_1: ic_h_w= [128, 171, 256], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 72.51611
TR,TC,TM,TN=2,512,64,8
igdn_1: ic_h_w= [128, 342, 512], oc_h_w= [128, 342, 512], w_aoffset=0, bias_aoffset=0, lat= 11.98092
TR,TC,TM,TN=4,72,3,8
syn_2: ic_h_w= [128, 342, 512], oc_h_w= [3, 1365, 2048], w_aoffset=51840, bias_aoffset=5, lat= 481.19773
save_png(s): 0.98598
syn_output: recon_c.png, h_w_c= [1365, 2048, 3]
```
**img/abigail-keenan-27293.png (Left); img/recon_i16c.png (Right)**
<div style="display: flex;">
    <img src="img/abigail-keenan-27293.png" width="45%" alt="First Image"/> 
    <div style="width: 2%;"></div>
    <img src="img/recon_i16c.png" width="45%" alt="Second Image"/>
</div>

## HLS Design



## Reference
[1] BallÃ© J, Laparra V, Simoncelli E P. End-to-end optimized image compression[J]. arXiv preprint arXiv:1611.01704, 2016.

[2] 
